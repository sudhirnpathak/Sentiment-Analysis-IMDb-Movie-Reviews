{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using LSTM\n",
    "\n",
    "In the previous notebook, we built a classifier using logistic regression for sentiment analysis of IMDb movie reviews.\n",
    "<br>In this notebook, we build the classifier using a deep learning technique called recurrent neural network (RNN). \n",
    "<br>We implement RNN using long short term memory (lstm) architecture, and PyTorch framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/sudhir/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing reviews**\n",
    "\n",
    "The dataset is discussed in detail in previous notebook. We have two lists, one for training, and other for testing, both consists of 25k reviews, first 12.5k reviews positive and rest 12.5k negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train_raw = []\n",
    "for line in open('./movie_data/full_train.txt', 'r'):\n",
    "    reviews_train_raw.append(line.strip())\n",
    "    \n",
    "reviews_test_raw = []\n",
    "for line in open('./movie_data/full_test.txt', 'r'):\n",
    "    reviews_test_raw.append(line.strip())\n",
    "    \n",
    "target = np.array([1 if i < 12500 else 0 for i in range(25000)])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**make sure to randomized it when training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic text preprocessing**\n",
    "\n",
    "Two steps undertaken in this text preprocessing: (1) making all words lowercase, (2) removing everything except words from the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High\\'s satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\\'t!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train_raw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(corpus):\n",
    "    \n",
    "    review_preprocessed = []\n",
    "    \n",
    "    for review in corpus:\n",
    "        \n",
    "        preprocessed = ' '.join([word for word in word_tokenize(review.lower()) if word.isalpha()])\n",
    "        review_preprocessed.append(preprocessed)\n",
    "        \n",
    "    return review_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train = text_preprocessing(reviews_train_raw)\n",
    "#reviews_test = text_preprocessing(reviews_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bromwell high is a cartoon comedy it ran at the same time as some other programs about school life such as teachers my years in the teaching profession lead me to believe that bromwell high satire is much closer to reality than is teachers the scramble to survive financially the insightful students who can see right through their pathetic teachers pomp the pettiness of the whole situation all remind me of the schools i knew and their students when i saw the episode in which a student repeatedly tried to burn down the school i immediately recalled at high a classic line inspector i here to sack one of your teachers student welcome to bromwell high i expect that many adults of my age think that bromwell high is far fetched what a pity that it is'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mapping word to index**\n",
    "\n",
    "Now, we create a dictionary that maps words into integer indices, with the convention that most frequently occuring words are assigned lower indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_combined = ' '.join(reviews_train)              # combining all reviews to get all words\n",
    "reviews_words = reviews_combined.split()\n",
    "\n",
    "word_counts = Counter(reviews_words)\n",
    "sorted_words = word_counts.most_common(len(reviews_words))\n",
    "\n",
    "vocab_to_index = {w: i+1 for i, (w, c) in enumerate(sorted_words)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this mapping, we started our indexing from 1, as keep 0 reserved for the padding purpose. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What happens if a new word appears in test set:** What about replacing these words by zero (motivated by padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_to_index_mapping(corpus, vocab_to_index):\n",
    "    \n",
    "    reviews_indexed = []\n",
    "    \n",
    "    for review in corpus:\n",
    "        \n",
    "        indexed = [vocab_to_index[word] for word in review.split()]\n",
    "        reviews_indexed.append(indexed)\n",
    "        \n",
    "    return reviews_indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train_index = vocab_to_index_mapping(reviews_train, vocab_to_index)\n",
    "#reviews_test_index = vocab_to_index_mapping(reviews_test, vocab_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making all reviews of same length**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "len_reviews = [len(review) for review in reviews_train_index]\n",
    "\n",
    "pd.Series(len_reviews).hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    25000.000000\n",
       "mean       229.809040\n",
       "std        170.707011\n",
       "min         10.000000\n",
       "25%        125.000000\n",
       "50%        172.000000\n",
       "75%        279.000000\n",
       "max       2454.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(len_reviews).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deal with both short and long reviews, we will pad or truncate all of our reviews to a specific length.\n",
    "<br> We define this length by sequence length, which is same as the number of time steps for LSTM layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixing_reviews_length(reviews_train_index, seq_length):\n",
    "    \n",
    "    modified_reviews = np.zeros((len(reviews_train_index), seq_length), dtype = int)\n",
    "    \n",
    "    for i, review in enumerate(reviews_train_index):\n",
    "        \n",
    "        len_review = len(review)\n",
    "        \n",
    "        if len_review <= seq_length:\n",
    "            pad_zeros = list(np.zeros(seq_length - len_review))\n",
    "            mod_review = pad_zeros + review\n",
    "        elif len_review > seq_length:\n",
    "            mod_review = review[0:seq_length]\n",
    "            \n",
    "        modified_reviews[i, :] = np.array(mod_review)\n",
    "        \n",
    "    print(modified_reviews.shape)\n",
    "    return modified_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 10)\n"
     ]
    }
   ],
   "source": [
    "feature_reviews = fixing_reviews_length(reviews_train_index, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's split the data for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(feature_reviews, target, train_size = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataloaders and Batching**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "valid_data = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle = True, batch_size = batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle = True, batch_size = batch_size)\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob = 0.4):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout = drop_prob, batch_first = True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        \n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        sig_out = self.sig(out)\n",
    "        \n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1]\n",
    "        \n",
    "        return sig_out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        \n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:39: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5... Step: 100... Loss: 0.614757... Val Loss: 0.672089\n",
      "Epoch: 1/5... Step: 200... Loss: 0.671380... Val Loss: 0.640673\n",
      "Epoch: 1/5... Step: 300... Loss: 0.615121... Val Loss: 0.635738\n",
      "Epoch: 1/5... Step: 400... Loss: 0.599936... Val Loss: 0.614623\n",
      "Epoch: 2/5... Step: 500... Loss: 0.624500... Val Loss: 0.631806\n",
      "Epoch: 2/5... Step: 600... Loss: 0.557410... Val Loss: 0.619600\n",
      "Epoch: 2/5... Step: 700... Loss: 0.634037... Val Loss: 0.612871\n",
      "Epoch: 2/5... Step: 800... Loss: 0.468270... Val Loss: 0.621490\n",
      "Epoch: 3/5... Step: 900... Loss: 0.360182... Val Loss: 0.688868\n",
      "Epoch: 3/5... Step: 1000... Loss: 0.344023... Val Loss: 0.715709\n",
      "Epoch: 3/5... Step: 1100... Loss: 0.408765... Val Loss: 0.670742\n",
      "Epoch: 3/5... Step: 1200... Loss: 0.473866... Val Loss: 0.673126\n",
      "Epoch: 4/5... Step: 1300... Loss: 0.157129... Val Loss: 0.848432\n",
      "Epoch: 4/5... Step: 1400... Loss: 0.298984... Val Loss: 0.793761\n",
      "Epoch: 4/5... Step: 1500... Loss: 0.256450... Val Loss: 0.858997\n",
      "Epoch: 4/5... Step: 1600... Loss: 0.402286... Val Loss: 0.857028\n",
      "Epoch: 5/5... Step: 1700... Loss: 0.107542... Val Loss: 1.199089\n",
      "Epoch: 5/5... Step: 1800... Loss: 0.167591... Val Loss: 1.120152\n",
      "Epoch: 5/5... Step: 1900... Loss: 0.064031... Val Loss: 1.082741\n",
      "Epoch: 5/5... Step: 2000... Loss: 0.273447... Val Loss: 1.128550\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab_to_index) + 1\n",
    "output_size = 1\n",
    "embedding_dim = 400\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "\n",
    "net = SentimentLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "\n",
    "lr = 0.001\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = lr)\n",
    "\n",
    "epochs = 5\n",
    "counter = 0\n",
    "print_every = 100\n",
    "clip = 5                  # gradient clipping\n",
    "\n",
    "net.train()\n",
    "\n",
    "for e in range(epochs):\n",
    "    \n",
    "    h = net.init_hidden(batch_size)\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "        h = tuple([each.data for each in h])\n",
    "        \n",
    "        net.zero_grad()\n",
    "        \n",
    "        inputs = inputs.type(torch.LongTensor)\n",
    "        output, h = net(inputs, h)\n",
    "        \n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        \n",
    "        nn.utils.clip_grad_norm(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if counter % print_every == 0:\n",
    "            \n",
    "            val_h = net.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            net.eval()\n",
    "            \n",
    "            for inputs, labels in valid_loader:\n",
    "                \n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "                \n",
    "                inputs = inputs.type(torch.LongTensor)\n",
    "                output, val_h = net(inputs, val_h)\n",
    "                val_loss = criterion(output.squeeze(), labels.float())\n",
    "                \n",
    "                val_losses.append(val_loss.item())\n",
    "                \n",
    "            net.train()\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
